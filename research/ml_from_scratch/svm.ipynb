{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "gqOUGaMLZ-Oi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kV6jwOqPiOnd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Support Vector Machine\n",
        "\n",
        "## Implementation of SVM from scratch"
      ]
    },
    {
      "metadata": {
        "id": "nYscIth1iO68",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1127
        },
        "outputId": "6979d478-29d8-49fd-a3fe-efab44d1fb86"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def load_data(path):\n",
        "  \"\"\"\n",
        "  Function to read csv from path/url\n",
        "  \"\"\"\n",
        "  names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
        "  dataset = pd.read_csv(path, names= names)\n",
        "  \n",
        "  # Select only two classes for binary classification\n",
        "  dataset1 = dataset[dataset[\"class\"] == \"Iris-setosa\"]\n",
        "  dataset2 = dataset[dataset[\"class\"] == \"Iris-versicolor\"]\n",
        "  dataset = pd.concat([dataset1,dataset2])  \n",
        "  dataset[\"class\"]= LabelEncoder().fit_transform(dataset[\"class\"])\n",
        "  return dataset\n",
        "\n",
        "def preprocess(dataset):\n",
        "  \"\"\"\n",
        "  Function to perform preprocessing of data\n",
        "  \"\"\"  \n",
        "  dataset.iloc[:,:-1] = MinMaxScaler().fit_transform(dataset.iloc[:,:-1])\n",
        "  return dataset\n",
        "\n",
        "def analyse(dataset):\n",
        "  \"\"\"\n",
        "  Function to analyse and plot \n",
        "  \"\"\"\n",
        "  \n",
        "\n",
        "def hinge_loss():\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  pass\n",
        "  \n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  dataset = load_data(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\")\n",
        "  dataset = preprocess(dataset)\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    sepal-length  sepal-width  petal-length  petal-width  class\n",
            "0       0.296296     0.625000      0.097561     0.058824      0\n",
            "1       0.222222     0.416667      0.097561     0.058824      0\n",
            "2       0.148148     0.500000      0.073171     0.058824      0\n",
            "3       0.111111     0.458333      0.121951     0.058824      0\n",
            "4       0.259259     0.666667      0.097561     0.058824      0\n",
            "5       0.407407     0.791667      0.170732     0.176471      0\n",
            "6       0.111111     0.583333      0.097561     0.117647      0\n",
            "7       0.259259     0.583333      0.121951     0.058824      0\n",
            "8       0.037037     0.375000      0.097561     0.058824      0\n",
            "9       0.222222     0.458333      0.121951     0.000000      0\n",
            "10      0.407407     0.708333      0.121951     0.058824      0\n",
            "11      0.185185     0.583333      0.146341     0.058824      0\n",
            "12      0.185185     0.416667      0.097561     0.000000      0\n",
            "13      0.000000     0.416667      0.024390     0.000000      0\n",
            "14      0.555556     0.833333      0.048780     0.058824      0\n",
            "15      0.518519     1.000000      0.121951     0.176471      0\n",
            "16      0.407407     0.791667      0.073171     0.176471      0\n",
            "17      0.296296     0.625000      0.097561     0.117647      0\n",
            "18      0.518519     0.750000      0.170732     0.117647      0\n",
            "19      0.296296     0.750000      0.121951     0.117647      0\n",
            "20      0.407407     0.583333      0.170732     0.058824      0\n",
            "21      0.296296     0.708333      0.121951     0.176471      0\n",
            "22      0.111111     0.666667      0.000000     0.058824      0\n",
            "23      0.296296     0.541667      0.170732     0.235294      0\n",
            "24      0.185185     0.583333      0.219512     0.058824      0\n",
            "25      0.259259     0.416667      0.146341     0.058824      0\n",
            "26      0.259259     0.583333      0.146341     0.176471      0\n",
            "27      0.333333     0.625000      0.121951     0.058824      0\n",
            "28      0.333333     0.583333      0.097561     0.058824      0\n",
            "29      0.148148     0.500000      0.146341     0.058824      0\n",
            "..           ...          ...           ...          ...    ...\n",
            "70      0.592593     0.500000      0.926829     1.000000      1\n",
            "71      0.666667     0.333333      0.731707     0.705882      1\n",
            "72      0.740741     0.208333      0.951220     0.823529      1\n",
            "73      0.666667     0.333333      0.902439     0.647059      1\n",
            "74      0.777778     0.375000      0.804878     0.705882      1\n",
            "75      0.851852     0.416667      0.829268     0.764706      1\n",
            "76      0.925926     0.333333      0.926829     0.764706      1\n",
            "77      0.888889     0.416667      0.975610     0.941176      1\n",
            "78      0.629630     0.375000      0.853659     0.823529      1\n",
            "79      0.518519     0.250000      0.609756     0.529412      1\n",
            "80      0.444444     0.166667      0.682927     0.588235      1\n",
            "81      0.444444     0.166667      0.658537     0.529412      1\n",
            "82      0.555556     0.291667      0.707317     0.647059      1\n",
            "83      0.629630     0.291667      1.000000     0.882353      1\n",
            "84      0.407407     0.416667      0.853659     0.823529      1\n",
            "85      0.629630     0.583333      0.853659     0.882353      1\n",
            "86      0.888889     0.458333      0.902439     0.823529      1\n",
            "87      0.740741     0.125000      0.829268     0.705882      1\n",
            "88      0.481481     0.416667      0.756098     0.705882      1\n",
            "89      0.444444     0.208333      0.731707     0.705882      1\n",
            "90      0.444444     0.250000      0.829268     0.647059      1\n",
            "91      0.666667     0.416667      0.878049     0.764706      1\n",
            "92      0.555556     0.250000      0.731707     0.647059      1\n",
            "93      0.259259     0.125000      0.560976     0.529412      1\n",
            "94      0.481481     0.291667      0.780488     0.705882      1\n",
            "95      0.518519     0.416667      0.780488     0.647059      1\n",
            "96      0.518519     0.375000      0.780488     0.705882      1\n",
            "97      0.703704     0.375000      0.804878     0.705882      1\n",
            "98      0.296296     0.208333      0.487805     0.588235      1\n",
            "99      0.518519     0.333333      0.756098     0.705882      1\n",
            "\n",
            "[100 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}