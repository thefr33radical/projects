{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "kV6jwOqPiOnd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Support Vector Machine\n",
        "\n",
        "#### Implementation of SVM from scratch\n",
        "\n",
        "##### References\n",
        "* https://machinelearningmastery.com/machine-learning-in-python-step-by-step/\n",
        "* http://machinelearningmastery.com/support-vector-machines-for-machine-learning/\n",
        "*  http://scikit-learn.org/stable/modules/svm.html\n",
        "* https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47"
      ]
    },
    {
      "metadata": {
        "id": "nYscIth1iO68",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f97bd821-d894-4a32-fa02-3a6fa1e24b3a"
      },
      "cell_type": "code",
      "source": [
        "#!pip install seaborn\n",
        "#!pip install matplotlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "def load_data(path):\n",
        "  \"\"\"\n",
        "  Function to read csv data from path/url\n",
        "  \"\"\"\n",
        "  names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
        "  dataset = pd.read_csv(path, names= names)\n",
        "  \n",
        "  # Select only two classes for binary classification\n",
        "  dataset1 = dataset[dataset[\"class\"] == \"Iris-setosa\"]\n",
        "  dataset2 = dataset[dataset[\"class\"] == \"Iris-versicolor\"]\n",
        "  dataset = pd.concat([dataset1,dataset2])  \n",
        "  dataset[\"class\"]= LabelEncoder().fit_transform(dataset[\"class\"])\n",
        "  return dataset\n",
        "\n",
        "def preprocess(dataset):\n",
        "  \"\"\"\n",
        "  Function to scale data between 0 & 1\n",
        "  \"\"\"  \n",
        "  dataset.iloc[:,:-1] = MinMaxScaler().fit_transform(dataset.iloc[:,:-1])\n",
        "  return dataset\n",
        "\n",
        "def analyse(dataset):\n",
        "  \"\"\"\n",
        "  Function to data distributions and plot the graphs\n",
        "  \"\"\"\n",
        "  print(dataset.describe())\n",
        "  plot_var = dataset\n",
        "  sns.pairplot(plot_var,hue=\"class\",markers=\"*\")\n",
        "  plt.show()\n",
        "  \n",
        "def predict(weights, feature):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    y_predict = []\n",
        "    for i in range(len(feature)):\n",
        "      y_predict.append(np.dot(weights.T,feature.iloc[i,:]))\n",
        "    return y_predict\n",
        "  \n",
        "def train(dataset):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  weights = np.array([random.randint(1,2)]*(len(dataset.columns)-1),dtype=float)\n",
        "  feature = dataset.iloc[:,:-1].copy()\n",
        "  print(weights)\n",
        "  y = dataset.iloc[:,-1]\n",
        "  epochs = 1\n",
        "  lr = 0.0001\n",
        "  \n",
        "  while epochs< 100:\n",
        "    \n",
        "    alpha = 1/epochs\n",
        "    predict_y = predict(weights, feature)\n",
        "    #print(\"predicted\", predict_y)\n",
        "    product = np.dot(y,predict_y)\n",
        "    #print(\"product\", product)\n",
        "    for i in range(len(weights)):\n",
        "      if(product>=1):\n",
        "        cost = 0\n",
        "        wts=   2 * alpha * weights[i]\n",
        "        weights[i]-=wts*lr\n",
        "\n",
        "      else:\n",
        "        cost = 1-product\n",
        "        wts = ( 2 * alpha * weights[i])- product \n",
        "        weights[i]-=wts*lr\n",
        "      epochs+=1\n",
        "  print(\"weights\", weights)\n",
        "  model = SVC(kernel=\"linear\")\n",
        "  model.fit(feature,y)\n",
        "  print(model.coef_)\n",
        "     \n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  dataset = load_data(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\")\n",
        "  dataset = preprocess(dataset)\n",
        "  #analyse(dataset)\n",
        "  train_input,train_output,test_input,test_output = train_test_split(dataset.iloc[:,:-1],dataset.iloc[:,-1], test_size =0.1)\n",
        "  train(dataset)\n",
        "  \n",
        "  "
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1.]\n",
            "weights [0.99962823 0.99962823 0.99962823 0.99962823]\n",
            "[[ 0.36369934 -1.12477515  1.82897479  1.51865788]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}